{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a2e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings #this to above classes we used to interact with llm model.\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph,END,START #this class we used to build stateful workflows in graphical form mei.\n",
    "from pydantic import BaseModel,Field,computed_field\n",
    "from typing import Annotated,List,Dict,TypedDict,Optional\n",
    "from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f03c04",
   "metadata": {},
   "source": [
    "# step:1) creating a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d19411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groq Model object\n",
    "model1 = ChatGroq(\n",
    "    model=\"groq/compound-mini\",\n",
    "    temperature=0.2\n",
    ")\n",
    "model1\n",
    "\n",
    "#openAI model object.\n",
    "model2 = ChatOpenAI(temperature=0.2)\n",
    "\n",
    "## Hugging Face endpoint define karo OPen source Model chat or Generation Model.\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "# Chat model object banao\n",
    "model3 = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe61715",
   "metadata": {},
   "source": [
    "# using pydantic class we are defining the structure field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357ed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "class SentimentSchema(BaseModel):\n",
    "    review : Annotated[str,Field(...,description=\"The user-provided review text.\")]\n",
    "    sentiment :Annotated[\n",
    "        Optional[\n",
    "            Literal['Positive','Negative','Unknown']\n",
    "            ],\n",
    "        Field(None,\n",
    "              description=\"The sentiment identified from the review. Must be 'Positive', 'Negative', or 'Unknown'.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97a7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    Issue: Annotated[\n",
    "        str,\n",
    "        Field(..., description=\"Identify the main issue reported by the customer.\")\n",
    "    ]\n",
    "\n",
    "    Urgency: Annotated[\n",
    "        Literal[\"High\", \"Medium\", \"Low\"],\n",
    "        Field(..., description=\"Determine the urgency level of the issue.\")\n",
    "    ]\n",
    "\n",
    "    Tone: Annotated[\n",
    "        Literal[\"frustrated\", \"disappointed\", \"angry\", \"neutral\"],\n",
    "        Field(..., description=\"Describe the emotional tone of the review.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ae376",
   "metadata": {},
   "source": [
    "# different type of parser object forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745c3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticOutputParser(pydantic_object=<class '__main__.SentimentSchema'>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an pydantic output parser class object\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=SentimentSchema)\n",
    "pydantic_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0dd263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticOutputParser(pydantic_object=<class '__main__.DiagnosisSchema'>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating pydantic parser object for dignonis schema class\n",
    "dignosis_parser = PydanticOutputParser(pydantic_object=DiagnosisSchema)\n",
    "dignosis_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00c5a7",
   "metadata": {},
   "source": [
    "# step:1) define the state or memory class with help of Typedict futhure we can create a graph object from stategraph class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf7e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review : str\n",
    "    sentiment: Literal['Positive','Negative','Unknown']\n",
    "    diagnosis : dict #why dict bcoz multiple factor we are dignosing\n",
    "    response : str #this will handle pos or neg response based on user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d24eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b7165cb790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a graph object by using stategraph class\n",
    "graph = StateGraph(ReviewState)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bad3cc",
   "metadata": {},
   "source": [
    "# step:2) adding nodes and edges to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152ee3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the sentiment_analysis nodes.\n",
    "def sentiment_analysis(state:ReviewState) -> ReviewState:\n",
    "    #now fetching the review text from state class.\n",
    "    text = state['review']\n",
    "    \n",
    "    #now creating a structure prompt that fetching the sentiment from review.\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        \n",
    "        You are a sentiment analysis expert.\n",
    "        Read the following user review carefully and classify its sentiment.\n",
    "\n",
    "        Review:\n",
    "        {review}\n",
    "\n",
    "        Your task:\n",
    "        - Identify whether the sentiment is **Positive**, **Negative**, or **Unknown**.\n",
    "        - Do not hallucinate; if the sentiment is unclear, return **Unknown**.\n",
    "\n",
    "        Return the result in the following format:\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "            \n",
    "        input_variables=['review'],\n",
    "        partial_variables={'format_instructions':pydantic_parser.get_format_instructions()}\n",
    "        \n",
    "    )\n",
    "    \n",
    "    #now passing the prompt to llm model to get sentiment structure creating sequential chain.\n",
    "    chain = prompt | model1 | pydantic_parser\n",
    "    \n",
    "    #now invoking the chain.\n",
    "    result = chain.invoke({'review':text})\n",
    "    \n",
    "    #now updating the memory with sentiment and returning the partial state .\n",
    "    \n",
    "    return {\n",
    "        'sentiment':result.sentiment\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ee3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dignosis(state:ReviewState) ->ReviewState:\n",
    "    #fetching the sentiment or review from state memory class\n",
    "    sentiment = state['sentiment']\n",
    "    review = state['review']\n",
    "    \n",
    "    #creating a prompt structure instruction based on negative sentiment or response\n",
    "    prompt_diagnosis = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a customer support assistant.\n",
    "        The following is a **negative review** from a customer:\n",
    "\n",
    "        Review: \"{review}\"\n",
    "\n",
    "        Return the result in this structured format:\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        input_variables=[\"review\"],\n",
    "        partial_variables={'format_instructions':dignosis_parser.get_format_instructions()}\n",
    "        \n",
    "    )\n",
    "    #now passing the prompt to llm model to get sentiment structure creating sequential chain.\n",
    "    chain = prompt_diagnosis | model1 | dignosis_parser\n",
    "    \n",
    "    #now invoking the chain.\n",
    "    result = chain.invoke({'review':review})\n",
    "    \n",
    "    #now updating the memory with sentiment and returning the partial state .\n",
    "    return {\n",
    "        'diagnosis':result.model_dump() # convert pydantic object into dict\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56294b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state:ReviewState) ->ReviewState:\n",
    "    #fetching the sentiment from state class\n",
    "    sent = state['sentiment']\n",
    "    \n",
    "    # Create a structured prompt for positive sentiment\n",
    "    prompt_positive = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        The customer left a positive review. \n",
    "        Review: \"{review}\"\n",
    "\n",
    "        Task:\n",
    "        Write a polite thank-you response to the customer \n",
    "        in 1–2 short sentences, expressing appreciation\n",
    "        and also ask user to give feedback on our website.\n",
    "        \"\"\",\n",
    "        input_variables=[\"review\"]\n",
    "    )\n",
    "    \n",
    "    #passing the prompt to LLM model show forming sequential chain.\n",
    "    chain = prompt_positive | model1 | parser\n",
    "    \n",
    "    #invoking the chain.\n",
    "    result = chain.invoke({'review':sent})\n",
    "    \n",
    "    #updating the response in state or memeory class and return partial state.\n",
    "    return {\n",
    "        'response':result\n",
    "    }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94891d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_response(state:ReviewState) ->ReviewState:\n",
    "    #fetching the dignosis result or negative review from state class.\n",
    "    dig = state['diagnosis']\n",
    "    revie = state['review']\n",
    "    \n",
    "    # create a structured empathetic response prompt\n",
    "    prompt_negative = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a helpful customer support assistant. \n",
    "        A customer has left a negative review about an electronic device. \n",
    "        You have the review text and a diagnosis of the problem.\n",
    "\n",
    "        Review:\n",
    "        {review}\n",
    "\n",
    "        Diagnosis:\n",
    "        - Issue: {Issue}\n",
    "        - Urgency: {Urgency}\n",
    "        - Tone: {Tone}\n",
    "\n",
    "        Task:\n",
    "        Write a professional and empathetic response to the customer in 1–2 short sentences. \n",
    "        Acknowledge their issue clearly, show understanding of their feelings, \n",
    "        and politely suggest possible next steps or support.\n",
    "\n",
    "        Response:\n",
    "        \"\"\",\n",
    "        input_variables=[\"review\", \"Issue\", \"Urgency\", \"Tone\"]\n",
    "    )\n",
    "    # build a chain → prompt → model\n",
    "    chain = prompt_negative | model1 | parser # model2 is your LLM\n",
    "\n",
    "    # run the chain with the review + unpacked diagnosis dict\n",
    "    response = chain.invoke({\n",
    "        \"review\": revie,\n",
    "        **dig  # expands dict into Issue, Urgency, Tone\n",
    "    })\n",
    "\n",
    "    # update state with generated reply\n",
    "    return {\"response\": response}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3096cab",
   "metadata": {},
   "source": [
    "# defining helper function that route the condition to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0d0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_condition(state:ReviewState) ->Literal['run_dignosis','positive_response']:\n",
    "    #fetching the sentiment from state class\n",
    "    sent = state['sentiment']\n",
    "    \n",
    "    if sent == \"Positive\":\n",
    "        return \"positive_response\"\n",
    "    elif sent == \"Negative\":\n",
    "        return \"run_dignosis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfab780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b7165cb790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding nodes to the graph.\n",
    "#nodes is nothing but python function which take state as input and perform some action inside it and rtn the state obect.\n",
    "graph.add_node(node=\"sentiment_analysis\",action=sentiment_analysis)\n",
    "graph.add_node(node='run_dignosis',action=run_dignosis)\n",
    "graph.add_node(node=\"positive_response\",action=positive_response)\n",
    "graph.add_node(node=\"negative_response\",action=negative_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b45791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b7165cb790>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding edges to graph.\n",
    "graph.add_edge(START,\"sentiment_analysis\")\n",
    "graph.add_conditional_edges(\"sentiment_analysis\",route_condition) # function that returns the key for the next node\n",
    "\n",
    "#adding edges\n",
    "graph.add_edge(\"run_dignosis\",\"negative_response\")\n",
    "\n",
    "#ending the nodes\n",
    "graph.add_edge(\"negative_response\",END)\n",
    "graph.add_edge(\"positive_response\",END)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d727c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the graph to show visual\n",
    "#graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7aa7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'I bought this smartphone last month and I am really disappointed. \\nThe battery drains very quickly and it hardly lasts half a day. \\nThe camera quality is poor, especially in low light, and the pictures come out blurry. \\nThe phone also hangs frequently while using normal apps. Overall, it feels overpriced and I regret purchasing it.',\n",
       " 'sentiment': 'Negative',\n",
       " 'diagnosis': {'Issue': 'Poor smartphone performance and value, with specific issues in battery life, camera quality, and responsiveness.',\n",
       "  'Urgency': 'High',\n",
       "  'Tone': 'disappointed'},\n",
       " 'response': \"I apologize for the disappointing experience with your smartphone, and I'm sorry to hear that it's not meeting your expectations in terms of battery life, camera quality, and performance. I understand your frustration, and I'd like to help - please contact our support team directly so we can troubleshoot the issue and explore possible solutions or alternatives for you.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = graph.compile()\n",
    "\n",
    "#review provided by user.\n",
    "text = \"\"\"I bought this smartphone last month and I am really disappointed. \n",
    "The battery drains very quickly and it hardly lasts half a day. \n",
    "The camera quality is poor, especially in low light, and the pictures come out blurry. \n",
    "The phone also hangs frequently while using normal apps. Overall, it feels overpriced and I regret purchasing it.\"\"\"\n",
    "\n",
    "#review saving them to state memory.\n",
    "initial_state = SentimentSchema(review=text)\n",
    "\n",
    "#invoking the workflow passing initial memory or stATe or sharing to throughout workflow .\n",
    "response = workflow.invoke(initial_state)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f297d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #text = \"This phone heats up quickly and the camera quality is very poor compared to what was advertised. Total waste of money.\"\n",
    "# text = \"\"\" I recently bought this laptop and I am very impressed with its performance.\n",
    "# The speed is excellent, even with multiple applications running at the same time.\n",
    "# The display quality is sharp and vibrant, which makes watching movies and working on presentations enjoyable.\n",
    "# The battery life is also great and lasts me almost a full day of work. \n",
    "# Overall, this laptop has exceeded my expectations and I would definitely recommend it to others.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
